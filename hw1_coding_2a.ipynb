{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "03581ae0-4c94-4602-85f0-d9690011d3c5",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "Frm06ZPq8noY"
   },
   "source": [
    "# CMU auto-graded notebook\n",
    "\n",
    "Before you turn these assignments in, make sure everything runs as expected. First, **restart the kernel** (in the menubar, select Kernel$\\rightarrow$Restart) and then **run all cells** (in the menubar, select Cell$\\rightarrow$Run All).\n",
    "\n",
    "Make sure you fill in any place that says `YOUR CODE HERE`, `<FILL IN>`, or \"YOUR ANSWER HERE.\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "76cd2df2-dbc6-4bc3-90fe-b5087afbea3a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "wfii2P5r8nob"
   },
   "source": [
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d66e2ea7-46c2-4135-9f07-2ec37f573953",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "Z1tnkgBl8nob"
   },
   "source": [
    "# CMU Machine Learning with Large Datasets\n",
    "\n",
    "## Homework 1 - Coding 2: Streaming Naive Bayes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "86b1730c-4299-4995-bf3a-25bc4b44d521",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "GxsV3uA48noc"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "# Who did you collaborate with on this assignment?\n",
    "# if no one, collaborators should contain an empty string,\n",
    "# else list your collaborators below\n",
    "\n",
    "collaborators = []\n",
    "print(collaborators)\n",
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "fe6b07e4-86f2-4150-ac78-e3c91532eb05",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "p5ux33if8noc"
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    collaborators\n",
    "except:\n",
    "    raise AssertionError(\"you did not list your collaborators, if any\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a8a72938-c969-408e-8682-ea013a26fa08",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "nLWy2qaP8nod"
   },
   "source": [
    "### (1a) Environment Setup\n",
    "\n",
    "Run the following cell to establish the runtime environment.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4b549c15-62a9-4fcf-944f-f07f988fa4ac",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "dq_Yf3an8nod"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[43mNote: you may need to restart the kernel using dbutils.library.restartPython() to use updated packages.\u001B[0m\nRequirement already satisfied: nose in /local_disk0/.ephemeral_nfs/cluster_libraries/python/lib/python3.10/site-packages (1.3.7)\nRequirement already satisfied: numpy in /databricks/python3/lib/python3.10/site-packages (1.23.5)\n\u001B[43mNote: you may need to restart the kernel using dbutils.library.restartPython() to use updated packages.\u001B[0m\n"
     ]
    }
   ],
   "source": [
    "# Ignore this cell if the environment already has the packages\n",
    "%pip install nose numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2083896d-f5b1-47bd-9d7e-4a5fb0e96dbd",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "yl9JFmyO8nod"
   },
   "outputs": [],
   "source": [
    "# imports that will be used in the notebook -- shouldn't need to import any other libraries\n",
    "\n",
    "import math\n",
    "import os\n",
    "import re\n",
    "from collections import Counter\n",
    "\n",
    "import numpy as np\n",
    "from nose.tools import assert_equal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2dfaa607-fd56-4f03-8468-d884efb412ac",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "nV7vgXw08noe"
   },
   "source": [
    "### (1b) Data Preparation\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0af7749a-b639-4aa5-bb77-cdf5b988978c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "k03fgbvg8noe"
   },
   "source": [
    "We use the Reuters Corpus (RCV1), which is a set of news stories split into a hierarchy of categories. There are three file sets. The two data sets with \"small\" in the name contain smaller subsamples of the full data set. They are provided for debugging and local tests. The final classification task should use the \"full\" one. Each data set is split into a train and test set, as indicated by the file suffix:\n",
    "\n",
    "- RCV1.full_train.txt\n",
    "- RCV1.full_test.txt\n",
    "- RCV1.small_train.txt\n",
    "- RCV1.small_test.txt\n",
    "- RCV1.very_small_train.txt\n",
    "- RCV1.very_small_test.txt\n",
    "\n",
    "Download the data using the link provided in the handout, and fill in the corresponding variables with their file paths in the following cell.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1bbdfd31-980a-4ace-a0b9-1067c56eb268",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Uncomment this cell if running on Databricks\n",
    "\n",
    "from urllib.parse import urlparse\n",
    "from pyspark import SparkFiles\n",
    "\n",
    "def get_file(url):\n",
    "    parsed_url = urlparse(url)\n",
    "    suffix = parsed_url.path.split('/')[-1]\n",
    "    sc.addFile(url)\n",
    "    path = SparkFiles.get(suffix)\n",
    "\n",
    "    return path\n",
    "\n",
    "FULL_TRAIN = get_file(\"https://cmu.box.com/shared/static/g37w2q552qaik60yubrd3aq95szgi7pc\")\n",
    "FULL_TEST = get_file(\"https://cmu.box.com/shared/static/305174svzxe3lqm0ps76fvaenhr37inj\")\n",
    "SMALL_TRAIN = get_file(\"https://cmu.box.com/shared/static/f1x91jode5ywofu5b6cm9tb6ynx3yoft\")\n",
    "SMALL_TEST = get_file(\"https://cmu.box.com/shared/static/0l8y7x3gtix2sjfb1ewzq10c8ayaokdd\")\n",
    "VERY_SMALL_TRAIN = get_file(\"https://cmu.box.com/shared/static/xiumqmfdge5muxhs9v2w7ma97hurqtqy\")\n",
    "VERY_SMALL_TEST = get_file(\"https://cmu.box.com/shared/static/np2s7tn5wvwuawad2vddygs76tbwt1f5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0cbb2ccb-cfc8-4e59-96a2-dcda9e58bc5c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "Yyo_7ru08noe"
   },
   "outputs": [],
   "source": [
    "FULL_TRAIN = get_file(\"https://cmu.box.com/shared/static/g37w2q552qaik60yubrd3aq95szgi7pc\")\n",
    "FULL_TEST = get_file(\"https://cmu.box.com/shared/static/305174svzxe3lqm0ps76fvaenhr37inj\")\n",
    "SMALL_TRAIN = get_file(\"https://cmu.box.com/shared/static/f1x91jode5ywofu5b6cm9tb6ynx3yoft\")\n",
    "SMALL_TEST = get_file(\"https://cmu.box.com/shared/static/0l8y7x3gtix2sjfb1ewzq10c8ayaokdd\")\n",
    "VERY_SMALL_TRAIN = get_file(\"https://cmu.box.com/shared/static/xiumqmfdge5muxhs9v2w7ma97hurqtqy\")\n",
    "VERY_SMALL_TEST = get_file(\"https://cmu.box.com/shared/static/np2s7tn5wvwuawad2vddygs76tbwt1f5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "52166ea6-5f78-42ff-9513-e227a9aebb9e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "_ZbUFSjw8noe"
   },
   "source": [
    "There are multiple class labels per document, meaning that there is more than one correct answer to the question \"What kind of news article is this?\"\n",
    "\n",
    "For this assignment, we will ignore all class labels except for those ending in CAT and just be classifying into the top-level nodes of the hierarchy:\n",
    "\n",
    "- CCAT: Corporate/Industrial\n",
    "- ECAT: Economics\n",
    "- GCAT: Government/Social\n",
    "- MCAT: Markets\n",
    "\n",
    "DO NOT change the following cell and just run it to set up the CAT labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "28fb6584-629d-4f26-ad47-427a4e4d460e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "7qKcB8ML8nof"
   },
   "outputs": [],
   "source": [
    "CAT_LABELS = ['CCAT', 'ECAT', 'GCAT', 'MCAT']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ad390138-d474-49fc-8c3a-d233c4f60f69",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "scv5Rgiz8nof"
   },
   "source": [
    "The data format is one document per line, with the class label(s) first (comma separated), a tab character, and then the document text.\n",
    "\n",
    "Run the following cell to take a glance at the first document of the small training data set.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0911ae96-4397-4617-bd9f-0412efeb663d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "F0CVLqKZ8nof"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C13,C21,CCAT\t The German government on Thursday awarded the first round of licences for basic public telephone services, opening the door for full competition to monopoly Deutsche Telekom. Kicking off the final stage of preparations ahead of liberalisation of European telecoms on January 1, 1998, Germany awarded licences for basic phone services to Vebacom GmbH, Britain's Colt Telecom Plc and NetCologne, a local operator.   The so-called &quot;class four&quot; licences cover basic voice telephone services for the public. That is the only service still under monopoly protection in Germany, where the telecoms market is expected to be worth more than 100 billion marks by the year 2000. In addition to the class 4 licences, the government awarded &quot;class 3&quot; licences to DBKom GmbH, the joint venture of a Mannesmann-led group and the German railway Deutsche Bahn AG, as well as to local operator VEW Telnet. Under a law passed this year, the class 3 licence allow owners of telecoms networks to lease capacity on these networks to other carriers or to companies for setting up internal communications networks. Previously, only Deutsche Telekom was allowed to do this. DBKom's licence is for national coverage, while the licence for VEW Telnet covers the northern cities of Muenster, Detmold and Arnsberg. Vebacom, the joint venture of energy group Veba AG and U.K.-based Cable and Wireless, welcomed the decision but said there were still questions about the conditions placed on licence holders. &quot;As the first new competitor (to Telekom), we received our network licence in October. Now we have our public phone licence and therefore all of the legal conditions to become a comprehensive carrier,&quot; Veba chairman Ulf Bohla told Reuters. Vebacom's licence is for national basic telephone services, while NetCologne's licence covers the greater Cologne region, and Colt's is for the cities of Frankfurt, Hamburg, Berlin, Potsdam and Munich, the Post and Telecommunications Ministry said. Post and Telecommunications Minister Wolfgang Boetsch told reporters late on Tuesday there were currently 11 applications for licences to provide public telephone services pending. Seven of the applications are for a national telephone service and the rest are for regional service. Next year will see some of the world's largest players on the telecommunications market and their German partners, several of Germany's biggest enterprises, make their final moves to compete against monopoly Telekom beginning in 1998. A dispute over the costs of the licences has been simmering for months. The government, seeking to plug yawning budget deficits, hopes to gain around 1.6 billion marks in one-off fees for new telecommunications licences. At around 40 million marks for a nationwide licence, industry representatives have called this an &quot;investment tax&quot; that would become just another excuse not to invest in Germany. &quot;We must clarify the licence conditions. The important question of the licence fees is still open,&quot; Bohla said. -- William Boston, Bonn Newsroom, 49 228 26097150\n\n"
     ]
    }
   ],
   "source": [
    "with open(SMALL_TRAIN, 'r') as f:\n",
    "    print(f.readline())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "71bac23b-92d4-494a-a549-6bca19cb1c10",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "ECKKg-Q88nof"
   },
   "source": [
    "### (1c) Data Processing\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "08695b2b-3277-4beb-831c-afe8acb519a0",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "IzF7Uocx8nof"
   },
   "source": [
    "To count the words, we need to tokenize the document text. In real-world practice, this may involve multiple steps, such as removing stop words and converting text to lowercase, which you learned in HW1: Entity Resolution. For this Naive Bayes part, we simplify the process by splitting only on words.\n",
    "\n",
    "Run the following cell to define the `tokenization(doc)` function.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "58afc51d-80a0-42c8-ba36-d7c10951f0f3",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "fp01Z4-K8nof"
   },
   "outputs": [],
   "source": [
    "# DO NOT change this function\n",
    "def tokenizeDoc(doc: str) -> list[str]:\n",
    "    \"\"\"\n",
    "    Convert input document text into tokenization features\n",
    "    Args:\n",
    "        doc: document text\n",
    "    Returns:\n",
    "        list: a list of tokens\n",
    "    \"\"\"\n",
    "    return re.findall('\\\\w+', doc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2f9789be-d2b3-46ea-9ff5-ba00892e9c72",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "X5s0UoRA8nof"
   },
   "source": [
    "As the handout instructs, streaming Naive Bayes loads one-line document at a time, use that document to update the classifier statistics, and then discard the document. After loading a line, we need a function to parse the line for classifier training.\n",
    "\n",
    "Implement `parseDatafileLine(datafileLine)` that takes a line (labels + document text) and return a list of labels and a list of tokens. You need to use the `tokenizeDoc(doc)` function defined above.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "41bad27b-b348-4361-ae7b-9495940416f9",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "4kuQlvTC8nof"
   },
   "outputs": [],
   "source": [
    "def parseDatafileLine(datafileLine: str):\n",
    "    parts = datafileLine.strip().split(\"\\t\", 1)  \n",
    "    if len(parts) < 2:\n",
    "        return [], []  \n",
    "    labels_part, doc_text = parts  \n",
    "    labels = labels_part.split(\",\")  \n",
    "    tokens = tokenizeDoc(doc_text)  \n",
    "    return labels, tokens\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5e4b7e67-009f-4ffa-b34a-285d735cef97",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "2FFa2bdI8nof"
   },
   "outputs": [],
   "source": [
    "\"\"\"Test parseDatafileLine(datafileLine)\"\"\"\n",
    "\n",
    "line_sample1 = \"C15,C151,CCAT\\tMcDonald's Corp said Thursday it raised its quarterly dividend 10 percent, to $0.0825 a share from $0.075.\"\n",
    "line_sample2 = \"C15,C151,CCAT\\tSix months to Sept 30, 1996       (in million rupees unless stated)\"\n",
    "\n",
    "assert_equal(parseDatafileLine(line_sample1),\n",
    "             (['C15', 'C151', 'CCAT'],\n",
    "              ['McDonald', 's', 'Corp', 'said', 'Thursday', 'it', 'raised', 'its',\n",
    "               'quarterly', 'dividend', '10', 'percent', 'to', '0', '0825', 'a',\n",
    "               'share', 'from', '0', '075']))\n",
    "\n",
    "assert_equal(parseDatafileLine(line_sample2),\n",
    "             (['C15', 'C151', 'CCAT'],\n",
    "              ['Six', 'months', 'to', 'Sept', '30', '1996', 'in', 'million',\n",
    "               'rupees', 'unless', 'stated']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "228dadfc-0260-4564-b78e-1440353c9f36",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "EjYi1Fca8nog"
   },
   "source": [
    "### 1(d) Training\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f8d39d2b-a1f3-4824-afc0-c072badcf9ec",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "R_zH3_lG8nog"
   },
   "source": [
    "Now, we are good for training. We will use a dictionary as the model to store the count statistics.\n",
    "\n",
    "As the handout instructs, the model contains five parts:\n",
    "\n",
    "- `y`: $(Y=y)$ for each label y the number of training instances of that class\n",
    "- `ys`: $(Y=*)$ here $*$ means anything, so this is just the total number of training instances\n",
    "- `y_w`: $(Y=y,W=w)$ number of times token w appears in a document with label y\n",
    "- `y_ws`: $(Y=y,W=*)$ total number of tokens for documents with label y\n",
    "- `vocabulary`: track the vocabulary for Laplace smoothing\n",
    "\n",
    "Recall that Laplace smoothing formula is\n",
    "\n",
    "$$p(W=w_i|Y=y)=\\frac{count(Y=y,W=w_i) + \\alpha}{count(Y=y,W=*)+ \\alpha|V|}$$\n",
    "where $|V|$ is the vocabulary.\n",
    "\n",
    "Implement `nbmodel()` by figuring out the proper variable types for each part and filling in the blank below.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e31469c5-689f-41f3-9fca-272e36a0ccc8",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "oMc-kFwL8nog"
   },
   "outputs": [],
   "source": [
    "def nbmodel() -> dict:\n",
    "    \"\"\"\n",
    "    Initialize and return a dictionary to store Naive Bayes model statistics.\n",
    "\n",
    "    Returns:\n",
    "        dict storing the required five parts:\n",
    "        - 'y': Dictionary storing count of training instances per class (Y=y).\n",
    "        - 'ys': Integer representing the total number of training instances (Y=*).\n",
    "        - 'y_w': Dictionary storing count of times each token appears in each class (Y=y, W=w).\n",
    "        - 'y_ws': Dictionary storing the total count of words per class (Y=y, W=*).\n",
    "        - 'vocabulary': Set of unique words encountered in the training data.\n",
    "    \"\"\"\n",
    "    return {\n",
    "        'y': {},          # Count of training instances per class {class_label: count}\n",
    "        'ys': 0,          # Total number of training instances\n",
    "        'y_w': {},        # Count of word occurrences per class {(class_label, word): count}\n",
    "        'y_ws': {},       # Total word count per class {class_label: total_word_count}\n",
    "        'vocabulary': set()  # Unique vocabulary for Laplace smoothing\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d7ca58bd-75a3-4a4f-a5f5-f482467f2497",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "5BUeeEaf8nog"
   },
   "source": [
    "Implement `trainNB(trainfile, model)` that loads one document at a time and uses that document to update the required statistics for the Naive Bayes classifier.\n",
    "\n",
    "Hint:\n",
    "\n",
    "1. We only use those lables ending in CAT, which defined in `CAT_LABELS` earlier. Therefore, you need to figure out a way to skip other labels.\n",
    "2. There are some documents with more than one CAT label. Treat those documents as multiple data instances (that is, add to the counters for\n",
    "   all labels ending in CAT). For instance, if one line contains CCAT and ECAT, use the same document text twice.\n",
    "3. It is not necessary to return the model here if you use proper types. Think about Python's mutable vs immutable types.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5bdf0727-e9c6-463d-8677-cf80d7860ea9",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "RnuvT2vN8nog"
   },
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "def trainNB(trainfile: str, model: dict):\n",
    "    \"\"\"\n",
    "    Train the Naive Bayes classifier by updating model statistics for each document.\n",
    "    \n",
    "    Args:\n",
    "        trainfile (str): Path to the training data file.\n",
    "        model (dict): Dictionary containing the Naive Bayes classifier model.\n",
    "    \"\"\"\n",
    "\n",
    "    with open(trainfile, 'r', encoding=\"utf-8\", errors=\"replace\") as f:\n",
    "        for line in f:\n",
    "            labels, tokens = parseDatafileLine(line)\n",
    "\n",
    "            model['ys'] += len(labels)\n",
    "\n",
    "            for label in labels:\n",
    "                if label.endswith(\"CAT\"): \n",
    "                    \n",
    "                    model['y'][label] = model['y'].get(label, 0) + 1  \n",
    "\n",
    "                    if label not in model['y_ws']:\n",
    "                        model['y_ws'][label] = 0  \n",
    "                    unique_tokens = set(tokens)\n",
    "\n",
    "                    for token in tokens:\n",
    "                        model['y_w'][(label, token)] = model['y_w'].get((label, token), 0) + 1\n",
    "                        model['y_ws'][label] += 1  # Increment total word count per class\n",
    "                    \n",
    "                    model['vocabulary'].update(unique_tokens)\n",
    "    model['vocabulary_size'] = len(model['vocabulary'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ff3756dc-f5db-483f-addf-01407573265e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "zJwHoz4m8nog"
   },
   "source": [
    "### 1(e) Test\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "650be61a-80ec-46d4-b96b-540d350c0a65",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "_N_CFBED8nog"
   },
   "source": [
    "For each line of documents, your classification code should get the best class $y$ and its log probabilities:\n",
    "\n",
    "$$ln(p(Y=y))+\\sum_{w_i} ln(p(W=w_i|Y=y))$$\n",
    "\n",
    "Notice that we use the natural logarithm here.\n",
    "\n",
    "Implement `testNB(testfile, model)` that uses the trained model to classify the test data and return a list of best classes, a list of max log probabilities (**rounding it to 4 decimal places**), and overall accuracy (**rounding it to 4 decimal places**). Please explicitly return in this specified order.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "fa6959a8-d2e1-469e-908e-fc4020b7b686",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "_gWRRfMu8nog"
   },
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "def testNB(testfile, model):\n",
    "    \"\"\"\n",
    "    Implement Naive Bayes classification.\n",
    "    \n",
    "    Args:\n",
    "        testfile (str): File path of the test data.\n",
    "        model (dict): The trained Naive Bayes model.\n",
    "    \n",
    "    Returns:\n",
    "        best_classes (list): List of predicted labels for each document.\n",
    "        log_probabilities (list): List of max log probabilities (rounded to 4 decimals).\n",
    "        accuracy (float): Classification accuracy (rounded to 4 decimals).\n",
    "    \"\"\"\n",
    "    best_classes = []\n",
    "    log_probabilities = []\n",
    "    correct_predictions = 0\n",
    "    total_documents = 0\n",
    "\n",
    "    class_counts = model['y']  \n",
    "    total_docs = model['ys']  \n",
    "    word_class_counts = model['y_w']  \n",
    "    total_words_per_class = model['y_ws'] \n",
    "    vocab_size = len(model['vocabulary'])  \n",
    "    alpha = 1  \n",
    "\n",
    "    with open(testfile, 'r', encoding=\"utf-8\", errors=\"replace\") as f:\n",
    "        for line in f:\n",
    "            total_documents += 1\n",
    "            true_labels, tokens = parseDatafileLine(line)\n",
    "\n",
    "            log_prob_per_label = {}\n",
    "\n",
    "            for label in class_counts:\n",
    "                log_prob = math.log(class_counts[label] / total_docs)\n",
    "\n",
    "                for token in tokens:\n",
    "                    token_count = word_class_counts.get((label, token), 0)\n",
    "                    total_tokens = total_words_per_class.get(label, 0) \n",
    "                    prob = (token_count + alpha) / (total_tokens + alpha * vocab_size)\n",
    "                    log_prob += math.log(prob)\n",
    "\n",
    "                log_prob_per_label[label] = log_prob\n",
    "\n",
    "            best_label = max(log_prob_per_label, key=log_prob_per_label.get)\n",
    "\n",
    "            max_log_prob = round(log_prob_per_label[best_label], 4)\n",
    "\n",
    "            best_classes.append(best_label)\n",
    "            log_probabilities.append(max_log_prob)\n",
    "\n",
    "            if best_label in true_labels:\n",
    "                correct_predictions += 1\n",
    "\n",
    "    accuracy = round(correct_predictions / total_documents, 4)\n",
    "\n",
    "    return best_classes, log_probabilities, accuracy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7a0bcf5e-bbd0-466d-86a5-3b9c041194d6",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "XodcTc5w8nog"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-9894.8165, -3913.8541, -1122.6353, -1611.2021, -702.3827, -1454.3791, -2219.3663, -2286.1059]\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m\n",
       "\u001B[0;31mAssertionError\u001B[0m                            Traceback (most recent call last)\n",
       "File \u001B[0;32m<command-2543043980408755>, line 10\u001B[0m\n",
       "\u001B[1;32m      7\u001B[0m assert_equal(best_classes,\n",
       "\u001B[1;32m      8\u001B[0m              [\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mMCAT\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mECAT\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mCCAT\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mECAT\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mCCAT\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mCCAT\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mECAT\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mCCAT\u001B[39m\u001B[38;5;124m'\u001B[39m])\n",
       "\u001B[1;32m      9\u001B[0m assert_equal(accuracy, \u001B[38;5;241m0.8750\u001B[39m)\n",
       "\u001B[0;32m---> 10\u001B[0m assert_equal(log_probabilities,\n",
       "\u001B[1;32m     11\u001B[0m              [\u001B[38;5;241m-\u001B[39m\u001B[38;5;241m9893.7804\u001B[39m, \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m3912.8180\u001B[39m, \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1121.5992\u001B[39m, \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1610.1660\u001B[39m,\n",
       "\u001B[1;32m     12\u001B[0m               \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m701.3466\u001B[39m, \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1453.3430\u001B[39m, \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m2218.3302\u001B[39m, \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m2285.0698\u001B[39m])\n",
       "\u001B[1;32m     13\u001B[0m assert_equal(accuracy, \u001B[38;5;241m0.8750\u001B[39m)\n",
       "\n",
       "File \u001B[0;32m/usr/lib/python3.10/unittest/case.py:845\u001B[0m, in \u001B[0;36mTestCase.assertEqual\u001B[0;34m(self, first, second, msg)\u001B[0m\n",
       "\u001B[1;32m    841\u001B[0m \u001B[38;5;124;03m\"\"\"Fail if the two objects are unequal as determined by the '=='\u001B[39;00m\n",
       "\u001B[1;32m    842\u001B[0m \u001B[38;5;124;03m   operator.\u001B[39;00m\n",
       "\u001B[1;32m    843\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n",
       "\u001B[1;32m    844\u001B[0m assertion_func \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_getAssertEqualityFunc(first, second)\n",
       "\u001B[0;32m--> 845\u001B[0m \u001B[43massertion_func\u001B[49m\u001B[43m(\u001B[49m\u001B[43mfirst\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43msecond\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmsg\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mmsg\u001B[49m\u001B[43m)\u001B[49m\n",
       "\n",
       "File \u001B[0;32m/usr/lib/python3.10/unittest/case.py:1051\u001B[0m, in \u001B[0;36mTestCase.assertListEqual\u001B[0;34m(self, list1, list2, msg)\u001B[0m\n",
       "\u001B[1;32m   1041\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21massertListEqual\u001B[39m(\u001B[38;5;28mself\u001B[39m, list1, list2, msg\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m):\n",
       "\u001B[1;32m   1042\u001B[0m     \u001B[38;5;124;03m\"\"\"A list-specific equality assertion.\u001B[39;00m\n",
       "\u001B[1;32m   1043\u001B[0m \n",
       "\u001B[1;32m   1044\u001B[0m \u001B[38;5;124;03m    Args:\u001B[39;00m\n",
       "\u001B[0;32m   (...)\u001B[0m\n",
       "\u001B[1;32m   1049\u001B[0m \n",
       "\u001B[1;32m   1050\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n",
       "\u001B[0;32m-> 1051\u001B[0m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43massertSequenceEqual\u001B[49m\u001B[43m(\u001B[49m\u001B[43mlist1\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mlist2\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmsg\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mseq_type\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mlist\u001B[39;49m\u001B[43m)\u001B[49m\n",
       "\n",
       "File \u001B[0;32m/usr/lib/python3.10/unittest/case.py:1033\u001B[0m, in \u001B[0;36mTestCase.assertSequenceEqual\u001B[0;34m(self, seq1, seq2, msg, seq_type)\u001B[0m\n",
       "\u001B[1;32m   1031\u001B[0m standardMsg \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_truncateMessage(standardMsg, diffMsg)\n",
       "\u001B[1;32m   1032\u001B[0m msg \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_formatMessage(msg, standardMsg)\n",
       "\u001B[0;32m-> 1033\u001B[0m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfail\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmsg\u001B[49m\u001B[43m)\u001B[49m\n",
       "\n",
       "File \u001B[0;32m/usr/lib/python3.10/unittest/case.py:675\u001B[0m, in \u001B[0;36mTestCase.fail\u001B[0;34m(self, msg)\u001B[0m\n",
       "\u001B[1;32m    673\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mfail\u001B[39m(\u001B[38;5;28mself\u001B[39m, msg\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m):\n",
       "\u001B[1;32m    674\u001B[0m     \u001B[38;5;124;03m\"\"\"Fail immediately, with the given message.\"\"\"\u001B[39;00m\n",
       "\u001B[0;32m--> 675\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mfailureException(msg)\n",
       "\n",
       "\u001B[0;31mAssertionError\u001B[0m: Lists differ: [-9894.8165, -3913.8541, -1122.6353, -1611.202[44 chars]1059] != [-9893.7804, -3912.818, -1121.5992, -1610.166,[41 chars]0698]\n",
       "\n",
       "First differing element 0:\n",
       "-9894.8165\n",
       "-9893.7804\n",
       "\n",
       "- [-9894.8165,\n",
       "+ [-9893.7804,\n",
       "-  -3913.8541,\n",
       "?      ^  --\n",
       "\n",
       "+  -3912.818,\n",
       "?      ^   +\n",
       "\n",
       "-  -1122.6353,\n",
       "-  -1611.2021,\n",
       "-  -702.3827,\n",
       "-  -1454.3791,\n",
       "+  -1121.5992,\n",
       "+  -1610.166,\n",
       "+  -701.3466,\n",
       "+  -1453.343,\n",
       "-  -2219.3663,\n",
       "?      ^  --\n",
       "\n",
       "+  -2218.3302,\n",
       "?      ^   ++\n",
       "\n",
       "-  -2286.1059]\n",
       "+  -2285.0698]"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "datasetInfos": [],
       "jupyterProps": {
        "ename": "AssertionError",
        "evalue": "Lists differ: [-9894.8165, -3913.8541, -1122.6353, -1611.202[44 chars]1059] != [-9893.7804, -3912.818, -1121.5992, -1610.166,[41 chars]0698]\n\nFirst differing element 0:\n-9894.8165\n-9893.7804\n\n- [-9894.8165,\n+ [-9893.7804,\n-  -3913.8541,\n?      ^  --\n\n+  -3912.818,\n?      ^   +\n\n-  -1122.6353,\n-  -1611.2021,\n-  -702.3827,\n-  -1454.3791,\n+  -1121.5992,\n+  -1610.166,\n+  -701.3466,\n+  -1453.343,\n-  -2219.3663,\n?      ^  --\n\n+  -2218.3302,\n?      ^   ++\n\n-  -2286.1059]\n+  -2285.0698]"
       },
       "metadata": {
        "errorSummary": "<span class='ansi-red-fg'>AssertionError</span>: Lists differ: [-9894.8165, -3913.8541, -1122.6353, -1611.202[44 chars]1059] != [-9893.7804, -3912.818, -1121.5992, -1610.166,[41 chars]0698]\n\nFirst differing element 0:\n-9894.8165\n-9893.7804\n\n- [-9894.8165,\n+ [-9893.7804,\n-  -3913.8541,\n?      ^  --\n\n+  -3912.818,\n?      ^   +\n\n-  -1122.6353,\n-  -1611.2021,\n-  -702.3827,\n-  -1454.3791,\n+  -1121.5992,\n+  -1610.166,\n+  -701.3466,\n+  -1453.343,\n-  -2219.3663,\n?      ^  --\n\n+  -2218.3302,\n?      ^   ++\n\n-  -2286.1059]\n+  -2285.0698]"
       },
       "removedWidgets": [],
       "sqlProps": null,
       "stackFrames": [
        "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
        "\u001B[0;31mAssertionError\u001B[0m                            Traceback (most recent call last)",
        "File \u001B[0;32m<command-2543043980408755>, line 10\u001B[0m\n\u001B[1;32m      7\u001B[0m assert_equal(best_classes,\n\u001B[1;32m      8\u001B[0m              [\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mMCAT\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mECAT\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mCCAT\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mECAT\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mCCAT\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mCCAT\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mECAT\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mCCAT\u001B[39m\u001B[38;5;124m'\u001B[39m])\n\u001B[1;32m      9\u001B[0m assert_equal(accuracy, \u001B[38;5;241m0.8750\u001B[39m)\n\u001B[0;32m---> 10\u001B[0m assert_equal(log_probabilities,\n\u001B[1;32m     11\u001B[0m              [\u001B[38;5;241m-\u001B[39m\u001B[38;5;241m9893.7804\u001B[39m, \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m3912.8180\u001B[39m, \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1121.5992\u001B[39m, \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1610.1660\u001B[39m,\n\u001B[1;32m     12\u001B[0m               \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m701.3466\u001B[39m, \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1453.3430\u001B[39m, \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m2218.3302\u001B[39m, \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m2285.0698\u001B[39m])\n\u001B[1;32m     13\u001B[0m assert_equal(accuracy, \u001B[38;5;241m0.8750\u001B[39m)\n",
        "File \u001B[0;32m/usr/lib/python3.10/unittest/case.py:845\u001B[0m, in \u001B[0;36mTestCase.assertEqual\u001B[0;34m(self, first, second, msg)\u001B[0m\n\u001B[1;32m    841\u001B[0m \u001B[38;5;124;03m\"\"\"Fail if the two objects are unequal as determined by the '=='\u001B[39;00m\n\u001B[1;32m    842\u001B[0m \u001B[38;5;124;03m   operator.\u001B[39;00m\n\u001B[1;32m    843\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m    844\u001B[0m assertion_func \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_getAssertEqualityFunc(first, second)\n\u001B[0;32m--> 845\u001B[0m \u001B[43massertion_func\u001B[49m\u001B[43m(\u001B[49m\u001B[43mfirst\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43msecond\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmsg\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mmsg\u001B[49m\u001B[43m)\u001B[49m\n",
        "File \u001B[0;32m/usr/lib/python3.10/unittest/case.py:1051\u001B[0m, in \u001B[0;36mTestCase.assertListEqual\u001B[0;34m(self, list1, list2, msg)\u001B[0m\n\u001B[1;32m   1041\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21massertListEqual\u001B[39m(\u001B[38;5;28mself\u001B[39m, list1, list2, msg\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m):\n\u001B[1;32m   1042\u001B[0m     \u001B[38;5;124;03m\"\"\"A list-specific equality assertion.\u001B[39;00m\n\u001B[1;32m   1043\u001B[0m \n\u001B[1;32m   1044\u001B[0m \u001B[38;5;124;03m    Args:\u001B[39;00m\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m   1049\u001B[0m \n\u001B[1;32m   1050\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[0;32m-> 1051\u001B[0m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43massertSequenceEqual\u001B[49m\u001B[43m(\u001B[49m\u001B[43mlist1\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mlist2\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmsg\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mseq_type\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mlist\u001B[39;49m\u001B[43m)\u001B[49m\n",
        "File \u001B[0;32m/usr/lib/python3.10/unittest/case.py:1033\u001B[0m, in \u001B[0;36mTestCase.assertSequenceEqual\u001B[0;34m(self, seq1, seq2, msg, seq_type)\u001B[0m\n\u001B[1;32m   1031\u001B[0m standardMsg \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_truncateMessage(standardMsg, diffMsg)\n\u001B[1;32m   1032\u001B[0m msg \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_formatMessage(msg, standardMsg)\n\u001B[0;32m-> 1033\u001B[0m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfail\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmsg\u001B[49m\u001B[43m)\u001B[49m\n",
        "File \u001B[0;32m/usr/lib/python3.10/unittest/case.py:675\u001B[0m, in \u001B[0;36mTestCase.fail\u001B[0;34m(self, msg)\u001B[0m\n\u001B[1;32m    673\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mfail\u001B[39m(\u001B[38;5;28mself\u001B[39m, msg\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m):\n\u001B[1;32m    674\u001B[0m     \u001B[38;5;124;03m\"\"\"Fail immediately, with the given message.\"\"\"\u001B[39;00m\n\u001B[0;32m--> 675\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mfailureException(msg)\n",
        "\u001B[0;31mAssertionError\u001B[0m: Lists differ: [-9894.8165, -3913.8541, -1122.6353, -1611.202[44 chars]1059] != [-9893.7804, -3912.818, -1121.5992, -1610.166,[41 chars]0698]\n\nFirst differing element 0:\n-9894.8165\n-9893.7804\n\n- [-9894.8165,\n+ [-9893.7804,\n-  -3913.8541,\n?      ^  --\n\n+  -3912.818,\n?      ^   +\n\n-  -1122.6353,\n-  -1611.2021,\n-  -702.3827,\n-  -1454.3791,\n+  -1121.5992,\n+  -1610.166,\n+  -701.3466,\n+  -1453.343,\n-  -2219.3663,\n?      ^  --\n\n+  -2218.3302,\n?      ^   ++\n\n-  -2286.1059]\n+  -2285.0698]"
       ],
       "type": "baseError"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\"\"\"DO NOT change this this cell and just run it to use the very small dataset to test your implementations\"\"\"\n",
    "very_small_model = nbmodel()\n",
    "trainNB(VERY_SMALL_TRAIN, very_small_model)\n",
    "best_classes, log_probabilities, accuracy = testNB(VERY_SMALL_TEST, very_small_model)\n",
    "print(log_probabilities)\n",
    "\n",
    "assert_equal(best_classes,\n",
    "             ['MCAT', 'ECAT', 'CCAT', 'ECAT', 'CCAT', 'CCAT', 'ECAT', 'CCAT'])\n",
    "assert_equal(accuracy, 0.8750)\n",
    "assert_equal(log_probabilities,\n",
    "             [-9893.7804, -3912.8180, -1121.5992, -1610.1660,\n",
    "              -701.3466, -1453.3430, -2218.3302, -2285.0698])\n",
    "assert_equal(accuracy, 0.8750)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "045e1886-d38d-4ec5-bdc9-663c97bdfb9a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "G8Stku3d8nog"
   },
   "source": [
    "### 1(f) Full Classification and Deliverable\n",
    "\n",
    "We are almost there! Let's wrap up this assignment.\n",
    "\n",
    "Implement your training and test functions on the full dataset to get the full classification results. Please note that you need to define a new model different from the `very_small_model` we have already tested.\n",
    "\n",
    "Write the full classification results to a file `full_result.txt` (please explicitly use this name). The output format should have one test result per line, and each line should have the format:\n",
    "\n",
    "$$\\text{[Label1, Label2, ...]<tab>Best class<tab>Log prob}$$\n",
    "\n",
    "where **[Label1, Label2, ...]** are the true labels of the test instance, **Best class** is the class with the maximum log probability, and the last field is the log probability.\n",
    "\n",
    "The last line of the file should include the accuracy.\n",
    "\n",
    "Use the following cell to write your code.\n",
    "\n",
    "Submit both this notebook and `full_result.txt` to Gradescope.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8fe59f1e-e739-41d8-a877-4ead905685cd",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "JzdWLHm58nog"
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m\n",
       "\u001B[0;31mAssertionError\u001B[0m                            Traceback (most recent call last)\n",
       "File \u001B[0;32m<command-2543043980408755>, line 10\u001B[0m\n",
       "\u001B[1;32m      7\u001B[0m assert_equal(best_classes,\n",
       "\u001B[1;32m      8\u001B[0m              [\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mMCAT\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mECAT\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mCCAT\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mECAT\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mCCAT\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mCCAT\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mECAT\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mCCAT\u001B[39m\u001B[38;5;124m'\u001B[39m])\n",
       "\u001B[1;32m      9\u001B[0m assert_equal(accuracy, \u001B[38;5;241m0.8750\u001B[39m)\n",
       "\u001B[0;32m---> 10\u001B[0m assert_equal(log_probabilities,\n",
       "\u001B[1;32m     11\u001B[0m              [\u001B[38;5;241m-\u001B[39m\u001B[38;5;241m9893.7804\u001B[39m, \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m3912.8180\u001B[39m, \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1121.5992\u001B[39m, \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1610.1660\u001B[39m,\n",
       "\u001B[1;32m     12\u001B[0m               \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m701.3466\u001B[39m, \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1453.3430\u001B[39m, \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m2218.3302\u001B[39m, \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m2285.0698\u001B[39m])\n",
       "\u001B[1;32m     13\u001B[0m assert_equal(accuracy, \u001B[38;5;241m0.8750\u001B[39m)\n",
       "\n",
       "File \u001B[0;32m/usr/lib/python3.10/unittest/case.py:845\u001B[0m, in \u001B[0;36mTestCase.assertEqual\u001B[0;34m(self, first, second, msg)\u001B[0m\n",
       "\u001B[1;32m    841\u001B[0m \u001B[38;5;124;03m\"\"\"Fail if the two objects are unequal as determined by the '=='\u001B[39;00m\n",
       "\u001B[1;32m    842\u001B[0m \u001B[38;5;124;03m   operator.\u001B[39;00m\n",
       "\u001B[1;32m    843\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n",
       "\u001B[1;32m    844\u001B[0m assertion_func \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_getAssertEqualityFunc(first, second)\n",
       "\u001B[0;32m--> 845\u001B[0m \u001B[43massertion_func\u001B[49m\u001B[43m(\u001B[49m\u001B[43mfirst\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43msecond\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmsg\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mmsg\u001B[49m\u001B[43m)\u001B[49m\n",
       "\n",
       "File \u001B[0;32m/usr/lib/python3.10/unittest/case.py:1051\u001B[0m, in \u001B[0;36mTestCase.assertListEqual\u001B[0;34m(self, list1, list2, msg)\u001B[0m\n",
       "\u001B[1;32m   1041\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21massertListEqual\u001B[39m(\u001B[38;5;28mself\u001B[39m, list1, list2, msg\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m):\n",
       "\u001B[1;32m   1042\u001B[0m     \u001B[38;5;124;03m\"\"\"A list-specific equality assertion.\u001B[39;00m\n",
       "\u001B[1;32m   1043\u001B[0m \n",
       "\u001B[1;32m   1044\u001B[0m \u001B[38;5;124;03m    Args:\u001B[39;00m\n",
       "\u001B[0;32m   (...)\u001B[0m\n",
       "\u001B[1;32m   1049\u001B[0m \n",
       "\u001B[1;32m   1050\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n",
       "\u001B[0;32m-> 1051\u001B[0m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43massertSequenceEqual\u001B[49m\u001B[43m(\u001B[49m\u001B[43mlist1\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mlist2\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmsg\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mseq_type\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mlist\u001B[39;49m\u001B[43m)\u001B[49m\n",
       "\n",
       "File \u001B[0;32m/usr/lib/python3.10/unittest/case.py:1033\u001B[0m, in \u001B[0;36mTestCase.assertSequenceEqual\u001B[0;34m(self, seq1, seq2, msg, seq_type)\u001B[0m\n",
       "\u001B[1;32m   1031\u001B[0m standardMsg \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_truncateMessage(standardMsg, diffMsg)\n",
       "\u001B[1;32m   1032\u001B[0m msg \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_formatMessage(msg, standardMsg)\n",
       "\u001B[0;32m-> 1033\u001B[0m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfail\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmsg\u001B[49m\u001B[43m)\u001B[49m\n",
       "\n",
       "File \u001B[0;32m/usr/lib/python3.10/unittest/case.py:675\u001B[0m, in \u001B[0;36mTestCase.fail\u001B[0;34m(self, msg)\u001B[0m\n",
       "\u001B[1;32m    673\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mfail\u001B[39m(\u001B[38;5;28mself\u001B[39m, msg\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m):\n",
       "\u001B[1;32m    674\u001B[0m     \u001B[38;5;124;03m\"\"\"Fail immediately, with the given message.\"\"\"\u001B[39;00m\n",
       "\u001B[0;32m--> 675\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mfailureException(msg)\n",
       "\n",
       "\u001B[0;31mAssertionError\u001B[0m: Lists differ: [-9894.8165, -3913.8541, -1122.6353, -1611.202[44 chars]1059] != [-9893.7804, -3912.818, -1121.5992, -1610.166,[41 chars]0698]\n",
       "\n",
       "First differing element 0:\n",
       "-9894.8165\n",
       "-9893.7804\n",
       "\n",
       "- [-9894.8165,\n",
       "+ [-9893.7804,\n",
       "-  -3913.8541,\n",
       "?      ^  --\n",
       "\n",
       "+  -3912.818,\n",
       "?      ^   +\n",
       "\n",
       "-  -1122.6353,\n",
       "-  -1611.2021,\n",
       "-  -702.3827,\n",
       "-  -1454.3791,\n",
       "+  -1121.5992,\n",
       "+  -1610.166,\n",
       "+  -701.3466,\n",
       "+  -1453.343,\n",
       "-  -2219.3663,\n",
       "?      ^  --\n",
       "\n",
       "+  -2218.3302,\n",
       "?      ^   ++\n",
       "\n",
       "-  -2286.1059]\n",
       "+  -2285.0698]"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "datasetInfos": [],
       "jupyterProps": {
        "ename": "AssertionError",
        "evalue": "Lists differ: [-9894.8165, -3913.8541, -1122.6353, -1611.202[44 chars]1059] != [-9893.7804, -3912.818, -1121.5992, -1610.166,[41 chars]0698]\n\nFirst differing element 0:\n-9894.8165\n-9893.7804\n\n- [-9894.8165,\n+ [-9893.7804,\n-  -3913.8541,\n?      ^  --\n\n+  -3912.818,\n?      ^   +\n\n-  -1122.6353,\n-  -1611.2021,\n-  -702.3827,\n-  -1454.3791,\n+  -1121.5992,\n+  -1610.166,\n+  -701.3466,\n+  -1453.343,\n-  -2219.3663,\n?      ^  --\n\n+  -2218.3302,\n?      ^   ++\n\n-  -2286.1059]\n+  -2285.0698]"
       },
       "metadata": {
        "errorSummary": "Command skipped"
       },
       "removedWidgets": [],
       "sqlProps": null,
       "stackFrames": [
        "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
        "\u001B[0;31mAssertionError\u001B[0m                            Traceback (most recent call last)",
        "File \u001B[0;32m<command-2543043980408755>, line 10\u001B[0m\n\u001B[1;32m      7\u001B[0m assert_equal(best_classes,\n\u001B[1;32m      8\u001B[0m              [\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mMCAT\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mECAT\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mCCAT\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mECAT\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mCCAT\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mCCAT\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mECAT\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mCCAT\u001B[39m\u001B[38;5;124m'\u001B[39m])\n\u001B[1;32m      9\u001B[0m assert_equal(accuracy, \u001B[38;5;241m0.8750\u001B[39m)\n\u001B[0;32m---> 10\u001B[0m assert_equal(log_probabilities,\n\u001B[1;32m     11\u001B[0m              [\u001B[38;5;241m-\u001B[39m\u001B[38;5;241m9893.7804\u001B[39m, \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m3912.8180\u001B[39m, \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1121.5992\u001B[39m, \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1610.1660\u001B[39m,\n\u001B[1;32m     12\u001B[0m               \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m701.3466\u001B[39m, \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1453.3430\u001B[39m, \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m2218.3302\u001B[39m, \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m2285.0698\u001B[39m])\n\u001B[1;32m     13\u001B[0m assert_equal(accuracy, \u001B[38;5;241m0.8750\u001B[39m)\n",
        "File \u001B[0;32m/usr/lib/python3.10/unittest/case.py:845\u001B[0m, in \u001B[0;36mTestCase.assertEqual\u001B[0;34m(self, first, second, msg)\u001B[0m\n\u001B[1;32m    841\u001B[0m \u001B[38;5;124;03m\"\"\"Fail if the two objects are unequal as determined by the '=='\u001B[39;00m\n\u001B[1;32m    842\u001B[0m \u001B[38;5;124;03m   operator.\u001B[39;00m\n\u001B[1;32m    843\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m    844\u001B[0m assertion_func \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_getAssertEqualityFunc(first, second)\n\u001B[0;32m--> 845\u001B[0m \u001B[43massertion_func\u001B[49m\u001B[43m(\u001B[49m\u001B[43mfirst\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43msecond\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmsg\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mmsg\u001B[49m\u001B[43m)\u001B[49m\n",
        "File \u001B[0;32m/usr/lib/python3.10/unittest/case.py:1051\u001B[0m, in \u001B[0;36mTestCase.assertListEqual\u001B[0;34m(self, list1, list2, msg)\u001B[0m\n\u001B[1;32m   1041\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21massertListEqual\u001B[39m(\u001B[38;5;28mself\u001B[39m, list1, list2, msg\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m):\n\u001B[1;32m   1042\u001B[0m     \u001B[38;5;124;03m\"\"\"A list-specific equality assertion.\u001B[39;00m\n\u001B[1;32m   1043\u001B[0m \n\u001B[1;32m   1044\u001B[0m \u001B[38;5;124;03m    Args:\u001B[39;00m\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m   1049\u001B[0m \n\u001B[1;32m   1050\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[0;32m-> 1051\u001B[0m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43massertSequenceEqual\u001B[49m\u001B[43m(\u001B[49m\u001B[43mlist1\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mlist2\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmsg\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mseq_type\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mlist\u001B[39;49m\u001B[43m)\u001B[49m\n",
        "File \u001B[0;32m/usr/lib/python3.10/unittest/case.py:1033\u001B[0m, in \u001B[0;36mTestCase.assertSequenceEqual\u001B[0;34m(self, seq1, seq2, msg, seq_type)\u001B[0m\n\u001B[1;32m   1031\u001B[0m standardMsg \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_truncateMessage(standardMsg, diffMsg)\n\u001B[1;32m   1032\u001B[0m msg \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_formatMessage(msg, standardMsg)\n\u001B[0;32m-> 1033\u001B[0m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfail\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmsg\u001B[49m\u001B[43m)\u001B[49m\n",
        "File \u001B[0;32m/usr/lib/python3.10/unittest/case.py:675\u001B[0m, in \u001B[0;36mTestCase.fail\u001B[0;34m(self, msg)\u001B[0m\n\u001B[1;32m    673\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mfail\u001B[39m(\u001B[38;5;28mself\u001B[39m, msg\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m):\n\u001B[1;32m    674\u001B[0m     \u001B[38;5;124;03m\"\"\"Fail immediately, with the given message.\"\"\"\u001B[39;00m\n\u001B[0;32m--> 675\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mfailureException(msg)\n",
        "\u001B[0;31mAssertionError\u001B[0m: Lists differ: [-9894.8165, -3913.8541, -1122.6353, -1611.202[44 chars]1059] != [-9893.7804, -3912.818, -1121.5992, -1610.166,[41 chars]0698]\n\nFirst differing element 0:\n-9894.8165\n-9893.7804\n\n- [-9894.8165,\n+ [-9893.7804,\n-  -3913.8541,\n?      ^  --\n\n+  -3912.818,\n?      ^   +\n\n-  -1122.6353,\n-  -1611.2021,\n-  -702.3827,\n-  -1454.3791,\n+  -1121.5992,\n+  -1610.166,\n+  -701.3466,\n+  -1453.343,\n-  -2219.3663,\n?      ^  --\n\n+  -2218.3302,\n?      ^   ++\n\n-  -2286.1059]\n+  -2285.0698]"
       ],
       "type": "baseError"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "def writeFullResults(trainfile: str, testfile: str, outputfile: str):\n",
    "    if not os.path.exists(testfile):\n",
    "        raise FileNotFoundError(f\"❌ Test file not found: {testfile}\")\n",
    "    if not os.path.exists(trainfile):\n",
    "        raise FileNotFoundError(f\"❌ Training file not found: {trainfile}\")\n",
    "\n",
    "    full_model = {\n",
    "        'y': {},  # Label counts\n",
    "        'ys': 0,  # Total number of training instances\n",
    "        'y_w': {},  # (Y=y, W=w): Count of words per label\n",
    "        'y_ws': {},  # (Y=y, W=*): Total word count per label\n",
    "        'vocabulary': set()\n",
    "    }\n",
    "\n",
    "    trainNB(trainfile, full_model)\n",
    "\n",
    "    best_classes, log_probabilities, accuracy = testNB(testfile, full_model)\n",
    "\n",
    "    print(f\"Opening test file: {testfile}\")\n",
    "\n",
    "    try:\n",
    "        with open(testfile, 'r', encoding='utf-8', errors='replace') as test_f, \\\n",
    "             open(outputfile, 'w', encoding='utf-8') as out_f:\n",
    "            \n",
    "            for i, line in enumerate(test_f):\n",
    "                true_labels, _ = parseDatafileLine(line)\n",
    "                out_f.write(f\"{true_labels}\\t{best_classes[i]}\\t{log_probabilities[i]:.4f}\\n\")\n",
    "\n",
    "            out_f.write(f\"Accuracy: {accuracy:.4f}\\n\")\n",
    "\n",
    "    except UnicodeDecodeError:\n",
    "        print(\"⚠️ UnicodeDecodeError: Retrying with 'latin1' encoding...\")\n",
    "        with open(testfile, 'r', encoding='latin1') as test_f, \\\n",
    "             open(outputfile, 'w', encoding='utf-8') as out_f:\n",
    "\n",
    "            for i, line in enumerate(test_f):\n",
    "                true_labels, _ = parseDatafileLine(line)\n",
    "                out_f.write(f\"{true_labels}\\t{best_classes[i]}\\t{log_probabilities[i]:.4f}\\n\")\n",
    "\n",
    "            out_f.write(f\"Accuracy: {accuracy:.4f}\\n\")\n",
    "\n",
    "writeFullResults(FULL_TRAIN, FULL_TEST, \"full_result.txt\")\n",
    "print(\"✅ Classification results saved to 'full_result.txt'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f2e0482c-b262-4fd9-bbfd-7da8c7917b48",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "hw1_coding_2a",
   "widgets": {}
  },
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "10605",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
